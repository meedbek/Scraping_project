{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1415f26d",
   "metadata": {},
   "source": [
    "Okay this if for noting : \n",
    "    our project goal is to scrap product label, price, descriptin and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce373a9",
   "metadata": {},
   "source": [
    "My first goal is to specify how to search for the accual product because as you may know if your searching for a specific product searching by its name may give you random result like if you tap in the search par PC you may get in the result a PC support for example.\n",
    "lucky for us their is an option in AMAZON which filters the results results by catalog\n",
    "So all i had to do is get into the page directly using your typical browser then copy the link which contains in the header all the informations needed about your product after that you can start your coding my fghiend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebc8a7",
   "metadata": {},
   "source": [
    "This is the link that we'll be working our starting point https://www.amazon.com/s?i=computers-intl-ship&bbn=16225007011&rh=n%3A16225007011%2Cn%3A193870011%2Cn%3A17923671011%2Cn%3A284822&dc&ds=v1%3A1UlRBmA3DTPGv8k%2FdC8o92iLhOYwmXL1F8TBpveBrQs&qid=1666031082&rnid=17923671011&ref=sr_nr_n_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dde17",
   "metadata": {},
   "source": [
    "first thing import necessary libraries that we'll be working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531baba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa6bc7",
   "metadata": {},
   "source": [
    "Then we load the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a81ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59243/2080977985.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/home/meedbek/DATA/UBUNTU/chromedriver',options=option)\n"
     ]
    }
   ],
   "source": [
    "# The option variable is to store more options before calling the driver\n",
    "option = webdriver.ChromeOptions()\n",
    "#option.add_argument('headless')\n",
    "\n",
    "#call the driver \n",
    "driver = webdriver.Chrome('/home/meedbek/DATA/UBUNTU/chromedriver',options=option)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c6f6a9",
   "metadata": {},
   "source": [
    "Open the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df25c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we get into the link \n",
    "\n",
    "link = \"https://www.amazon.com/s?i=computers-intl-ship&bbn=16225007011&rh=n%3A16225007011%2Cn%3A193870011%2Cn%3A17923671011%2Cn%3A284822&dc&ds=v1%3A1UlRBmA3DTPGv8k%2FdC8o92iLhOYwmXL1F8TBpveBrQs&qid=1666031082&rnid=17923671011&ref=sr_nr_n_3\"\n",
    "\n",
    "driver.get(link)\n",
    "#we ll loading directly to the page were the graphics cards are listed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b476b4",
   "metadata": {},
   "source": [
    "Tthis is an instance of the WebDriverWait object, this object will allow to wait for pages to load or certain html tags to appear before continuing the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a91639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver,60) #the 60 refers to the timeout variable before stoping cause we can't wait for pages to load for infinite time\n",
    "wait5 = WebDriverWait(driver, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48d041a",
   "metadata": {},
   "source": [
    "This is so straightforward after loading the page we need to search for all the links  then iterate into each one of them click to link get your data get back and your closely done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136849dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will wait for the presence of elements we re locating using XPATH\n",
    "xpath_links = \"//a[contains(@class, 'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal')]\"\n",
    "graphics = wait.until(EC.presence_of_all_elements_located((By.XPATH, xpath_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95e947a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7582728",
   "metadata": {},
   "source": [
    "we have noticed that the  number of graphic card returned by the graphics variable does not match the number of the graphic card in the website page so in the script below we'll be checking if any of the links returned are duplicated or their are links that we cannot see on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b36578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2])\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "for graphic in graphics:\n",
    "    key = graphic.get_attribute('href') \n",
    "    if key in dictionary.keys():\n",
    "        dictionary[key] = dictionary[key] + 1\n",
    "    else:\n",
    "        dictionary[key] = 1\n",
    "        \n",
    "print(dictionary.values())\n",
    "print(len(dictionary.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3795fee2",
   "metadata": {},
   "source": [
    "as we predicted we find most of the links found dublicted but the number distinct link does indeed match the number found on the page so we ll be iterating through this distinct list or dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538de5d",
   "metadata": {},
   "source": [
    "on thing we can do is go into each of the links, get informations needed about the product get back again, then when all the products were seen on one page we can go to the next one.\n",
    "But this not optimal we can get all the links at one from all the pages and when we're done then we go through each link one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682486b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking how many of the buttons does have this class\n",
    "nextButton = \"//a[contains(@class, 's-pagination-item s-pagination-next s-pagination-button s-pagination-separator')]\"\n",
    "len(driver.find_elements(By.XPATH,nextButton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74592833",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "738339ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we save all links\n",
    "done = False\n",
    "while(not done):\n",
    "    wait.until(EC.presence_of_all_elements_located((By.XPATH, xpath_links)))\n",
    "    time.sleep(1)\n",
    "    graphics = driver.find_elements(By.XPATH,xpath_links)\n",
    "    for graphic in graphics:\n",
    "        key = graphic.get_attribute('href') \n",
    "        if key in dictionary.keys():\n",
    "            dictionary[key] = dictionary[key] + 1\n",
    "        else:\n",
    "            dictionary[key] = 1\n",
    "    try :\n",
    "        nextp = wait5.until(EC.presence_of_element_located((By.XPATH, nextButton)))\n",
    "    except :\n",
    "        nextp = None\n",
    "    if nextp != None :\n",
    "        nextp.click()\n",
    "    else :\n",
    "        done = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c48dc723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many link found\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f6b04",
   "metadata": {},
   "source": [
    "we got the links now we save them into a json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bc66c",
   "metadata": {},
   "source": [
    "but before doing so we're gonna reset all the values of the dict to 0 this will be helpfull afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab7045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b0fcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in list(links.keys()):\n",
    "    links[link] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04d1588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02bad7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"links.json\", \"w\") as fp:\n",
    "    json.dump(dictionary,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c9ee1",
   "metadata": {},
   "source": [
    "This is a new section after getting all links its time get into each of the links and get all the inforamtions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b122c5cd",
   "metadata": {},
   "source": [
    "**This is the final code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc5254",
   "metadata": {},
   "source": [
    "Read the json file we saved earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46440491",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('links.json') as json_file:\n",
    "   links = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f0995",
   "metadata": {},
   "source": [
    "If the scraping stopped for some reason you can load newlinks.json instead this link so that you don't from start all over again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa78fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('newlinks.json') as json_file:\n",
    "#     links = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79df31e",
   "metadata": {},
   "source": [
    "To understand more links.json is a list of keys values, the keys represent each link and the value represent if it was visited or not so each time the scrapping stops for a reason or another you can continue from where started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef7bd9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function return the xpath of any html tag given, the className is a list of tags in form of a String\n",
    "def xpath(className, context=False):\n",
    "    if context==True:\n",
    "        return \".//*[contains(@class,'\"+className+\"')]\"\n",
    "    return \"//*[contains(@class,'\"+className+\"')]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8693a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this allows to retreive the rating from the text their is an example below\n",
    "def retreiveRating(text):    \n",
    "    if text == None:\n",
    "        return None\n",
    "    digits = [ i for i in text if i.isdigit()]\n",
    "    if len(digits) == 2:\n",
    "        return digits[0]+'.'+digits[1]\n",
    "    return digits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d7ce870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreiveRating(\"the rating is 4-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a6098",
   "metadata": {},
   "source": [
    "We define the classes of each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9b7a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelClass = \"a-size-large product-title-word-break\"\n",
    "priceClass = \"a-price-whole\"\n",
    "price2 = \"a-price-fraction\"\n",
    "\n",
    "descriptionID = \"productDescription\" #value is in p/span\n",
    "ratingClass = \"a-size-medium a-color-base\" \n",
    "\n",
    "buttonReviewsClass = \"a-link-emphasis a-text-bold\"\n",
    "\n",
    "reviewClass = \"a-section celwidget\"\n",
    "reviewTitleClass = \"a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold\"\n",
    "\n",
    "numberOfStarsClass = \"a-icon-alt\"\n",
    "\n",
    "reviewInforamtionClass = \"a-size-base a-color-secondary review-date\"\n",
    "\n",
    "reviewContentClass = \"a-size-base review-text review-text-content\" #value span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daac5f3",
   "metadata": {},
   "source": [
    "we just do some necessary initiations like the variable that will the data and the driver etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22102f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59243/59067237.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/home/meedbek/DATA/UBUNTU/chromedriver', options=option)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "data['data'] = []\n",
    "listOfGraphics = data['data']\n",
    "\n",
    "keys = list(links.keys())\n",
    "\n",
    "option = webdriver.ChromeOptions()\n",
    "#option.add_argument('headless')\n",
    "driver = webdriver.Chrome('/home/meedbek/DATA/UBUNTU/chromedriver', options=option)\n",
    "wait = WebDriverWait(driver,20) \n",
    "wait5 = WebDriverWait(driver, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec1632",
   "metadata": {},
   "source": [
    "Start Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d86d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/meedbek/DATA/UBUNTU/scrap_env/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:393: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "/media/meedbek/DATA/UBUNTU/scrap_env/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:341: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter : 1\n",
      "Counter : 2\n",
      "Counter : 3\n",
      "Counter : 4\n",
      "Counter : 5\n",
      "Counter : 6\n",
      "Counter : 7\n",
      "Counter : 8\n",
      "Counter : 9\n",
      "Counter : 10\n",
      "Counter : 11\n",
      "Counter : 12\n",
      "Counter : 13\n",
      "Counter : 14\n",
      "Counter : 15\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in range(len(keys)) :\n",
    "    print(\"Counter :\", counter)\n",
    "    if(links[keys[i]] == 1):\n",
    "        counter += 1\n",
    "        continue \n",
    "    if(counter%100 == 0):    \n",
    "        counter == 0\n",
    "        with open(\"newlinks.json\", \"w\") as fp:\n",
    "            json.dump(links,fp)\n",
    "        with open (\"data.json\", \"w\") as fp:\n",
    "            json.dump(data,fp)\n",
    "    \n",
    "    driver.get(keys[i])\n",
    "    label = wait.until(EC.presence_of_element_located((By.XPATH, xpath(labelClass)))).text\n",
    "    try :\n",
    "        price = wait5.until(EC.presence_of_element_located((By.XPATH, xpath(priceClass)))).text\n",
    "    except : \n",
    "        price = None\n",
    "    try :\n",
    "        cents = wait5.until(EC.presence_of_element_located((By.XPATH, xpath(price2)))).text\n",
    "    except : \n",
    "        cents = None\n",
    "    try : \n",
    "        descr = wait5.until(EC.presence_of_element_located((By.ID, descriptionID)))\n",
    "        description = descr.find_element_by_xpath(\"p/span\").text\n",
    "    except :\n",
    "        description = None\n",
    "    try :\n",
    "        rating = wait5.until(EC.presence_of_element_located((By.XPATH, xpath(ratingClass)))).text.split(' ')[0]\n",
    "    except : \n",
    "        rating = None\n",
    "    \n",
    "    try :\n",
    "        prix = price+'.'+cents\n",
    "        if('..' in prix):\n",
    "            prix = '.'.join(prix.split('..'))\n",
    "    except :\n",
    "        prix = None \n",
    "        \n",
    "    listOfGraphics.append({'label' : label, 'price' : prix,'description' : description, 'rating' : rating})\n",
    "    try :\n",
    "        wait5.until(EC.presence_of_element_located((By.XPATH, xpath(buttonReviewsClass)))).click()\n",
    "        reviews = wait.until(EC.presence_of_all_elements_located((By.XPATH, xpath(reviewClass))))\n",
    "        listOfGraphics[-1]['Reviews'] = []\n",
    "        RE = listOfGraphics[-1]['Reviews']\n",
    "        for j in range(len(reviews)) :\n",
    "            waitR = WebDriverWait(reviews[j],0.5) \n",
    "            try :\n",
    "                reviewTitle = waitR.until(EC.presence_of_element_located((By.XPATH, xpath(reviewTitleClass,context=True)))).text \n",
    "            except :\n",
    "                reviewTitle = None\n",
    "            try : \n",
    "                reviewRating = waitR.until(EC.presence_of_element_located((By.TAG_NAME, 'i'))).get_attribute('class') \n",
    "            except : \n",
    "                reviewRating = None\n",
    "            try : \n",
    "                reviewInforamtion = waitR.until(EC.presence_of_element_located((By.XPATH, xpath(reviewInforamtionClass,context=True)))).text \n",
    "            except : \n",
    "                reviewInforamtion = None \n",
    "            try : \n",
    "                reviewContent = waitR.until(EC.presence_of_element_located((By.XPATH, xpath(reviewContentClass,context=True)))).find_element_by_tag_name('span').text  \n",
    "            except :\n",
    "                reviewContent = None\n",
    "            RE.append({'title' : reviewTitle, 'rating' : retreiveRating(reviewRating), 'location-date': reviewInforamtion, 'text' : reviewContent})\n",
    "    except : \n",
    "        continue\n",
    "    finally :\n",
    "        counter += 1\n",
    "        links[keys[i]] = 1 \n",
    "with open(\"newlinks.json\", \"w\") as fp:\n",
    "            json.dump(links,fp)\n",
    "with open (\"dataEnd.json\", \"w\") as fp:\n",
    "    json.dump(data,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links)\n",
    "rest = 0\n",
    "for value in links.values():\n",
    "    if value == 1:\n",
    "        rest += 1\n",
    "rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2dcbe9",
   "metadata": {},
   "source": [
    "Now afer we had all this files we need to merge all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "files.append('data823')\n",
    "files.append('data125')\n",
    "files.append('data5')\n",
    "files.append('dataEnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f61780",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f19511",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with open(file+'.json') as json_file:\n",
    "        final = final + json.load(json_file)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti = {'data' : final}\n",
    "with open (\"completeData.json\", \"w\") as fp:\n",
    "    json.dump(dicti,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee126ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
